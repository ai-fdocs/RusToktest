# Tenant Resolver V2 Migration Guide

> **Date:** 2026-02-12  
> **Sprint:** Sprint 2 - Simplification  
> **Status:** ðŸš§ In Progress

---

## Overview

This document describes the migration from the complex manual tenant caching infrastructure to the simplified **Tenant Resolver V2** powered by `moka` cache.

### Motivation

The original tenant resolver (`apps/server/src/middleware/tenant.rs`) implements:
- Manual cache stampede protection with in-flight request tracking
- Dual caching (positive + negative caching)
- Redis pub/sub for cache invalidation
- Manual metrics tracking
- Complex key management

**Problems:**
1. **Complexity:** ~700 lines of infrastructure code
2. **Error-prone:** Manual request coalescing can have race conditions
3. **Hard to test:** Tight coupling with Redis and complex state
4. **Maintenance burden:** Custom metrics, key versioning, etc.

**Solution:** Use `moka`, which provides:
- Built-in cache stampede protection
- Automatic TTL and eviction
- Thread-safe operations
- Simple API
- Well-tested library

---

## Architecture Comparison

### Before (V1)

```
Request â†’ TenantCacheInfrastructure
          â”œâ”€â”€ Check negative cache
          â”œâ”€â”€ Check positive cache
          â”œâ”€â”€ In-flight request tracking (manual)
          â”‚   â””â”€â”€ Notify/await pattern
          â”œâ”€â”€ Database load
          â”œâ”€â”€ Set cache + negative cache
          â””â”€â”€ Metrics tracking (manual)
```

**Code complexity:** ~700 lines  
**Dependencies:** Custom cache backends, Redis pub/sub, manual coalescing  
**Cache stampede protection:** Manual implementation with `Arc<Notify>`

### After (V2)

```
Request â†’ TenantResolver
          â””â”€â”€ Moka cache.try_get_with()
              â”œâ”€â”€ Automatic cache check
              â”œâ”€â”€ Automatic request coalescing
              â”œâ”€â”€ Database load (on miss)
              â””â”€â”€ Automatic cache population
```

**Code complexity:** ~250 lines  
**Dependencies:** `moka` crate only  
**Cache stampede protection:** Built-in via `try_get_with()`

---

## API Changes

### Creating the resolver

**V1 (implicit via AppContext):**
```rust
// Infrastructure initialized in middleware
let infra = TenantCacheInfrastructure::new();
ctx.shared_store.insert(infra);
```

**V2 (explicit):**
```rust
use crate::middleware::tenant_v2::{TenantResolver, TenantResolverConfig};

// With default config
let resolver = TenantResolver::new(db);

// With custom config
let config = TenantResolverConfig {
    max_capacity: 5_000,
    time_to_live: Duration::from_secs(600),
    time_to_idle: Duration::from_secs(120),
};
let resolver = TenantResolver::with_config(db, config);
```

### Resolving tenants

**V1:**
```rust
// Complex internal flow with cache keys, negative cache, etc.
let context = infra.get_or_load_with_coalescing(&cache_key, loader).await?;
```

**V2:**
```rust
use crate::middleware::tenant_v2::TenantKey;

// By UUID
let tenant = resolver.resolve(TenantKey::Uuid(tenant_id)).await?;

// By slug
let tenant = resolver.resolve(TenantKey::Slug("my-tenant".to_string())).await?;

// By host
let tenant = resolver.resolve(TenantKey::Host("tenant.example.com".to_string())).await?;
```

### Cache invalidation

**V1:**
```rust
// Multiple functions with Redis pub/sub
invalidate_tenant_cache_by_uuid(ctx, tenant_id).await;
invalidate_tenant_cache_by_slug(ctx, slug).await;
invalidate_tenant_cache_by_host(ctx, host).await;
```

**V2:**
```rust
// Direct resolver methods
resolver.invalidate_by_uuid(tenant_id).await;
resolver.invalidate_by_slug(slug).await;
resolver.invalidate_by_host(host).await;
resolver.invalidate_all().await;  // Clear all
```

### Getting metrics

**V1:**
```rust
let stats = tenant_cache_stats(ctx).await;
// Returns complex TenantCacheStats with 10 fields
```

**V2:**
```rust
let stats = resolver.stats();
// Returns simple TenantCacheStats with 2 fields
```

---

## Migration Steps

### Phase 1: Side-by-side deployment (Week 2)

1. **Deploy V2 alongside V1** (both active)
   ```rust
   // In app.rs or middleware setup
   let resolver_v2 = Arc::new(TenantResolver::new(ctx.db.clone()));
   ctx.shared_store.insert(resolver_v2);
   ```

2. **Add feature flag** to control which resolver is used
   ```rust
   const USE_TENANT_V2: bool = std::env::var("RUSTOK_TENANT_V2")
       .ok()
       .and_then(|v| v.parse().ok())
       .unwrap_or(false);
   ```

3. **Shadow mode:** Use V2 but don't fail if it errors
   ```rust
   if USE_TENANT_V2 {
       match resolver_v2.resolve(key).await {
           Ok(tenant) => return Ok(tenant),
           Err(e) => {
               tracing::warn!(error = %e, "V2 resolver failed, falling back to V1");
               // Fall through to V1
           }
       }
   }
   // V1 logic continues...
   ```

### Phase 2: Testing (Week 2-3)

1. **Integration tests**
   ```bash
   RUSTOK_TENANT_V2=true cargo test --test integration::tenant_*
   ```

2. **Load testing**
   - Compare V1 vs V2 performance
   - Verify cache stampede protection works
   - Check memory usage

3. **Monitor metrics:**
   - Cache hit rate
   - Database query count
   - P95/P99 latency
   - Error rate

### Phase 3: Cutover (Week 3)

1. **Enable V2 by default**
   ```rust
   const USE_TENANT_V2: bool = true;
   ```

2. **Remove V1 fallback** after 1 week of stable operation

3. **Delete old code** (`tenant.rs` V1 implementation)

---

## Benefits

### Simplification
- **70% less code** (~700 â†’ ~250 lines)
- **No manual coalescing** logic
- **No custom metrics** tracking
- **No Redis dependency** for basic caching

### Reliability
- **Well-tested library:** moka has extensive test coverage
- **No race conditions:** cache stampede protection is proven
- **Simpler debugging:** less custom infrastructure

### Performance
- **Faster cache lookups:** moka uses lock-free reads
- **Better memory efficiency:** automatic eviction policies
- **No serialization overhead:** stores `Arc<TenantContext>` directly

---

## Testing Strategy

### Unit Tests

```rust
#[tokio::test]
async fn test_tenant_resolver_caches_results() {
    let db = mock_database_with_tenant();
    let resolver = TenantResolver::new(db);
    
    // First call - hits database
    let result1 = resolver.resolve(TenantKey::Uuid(tenant_id)).await;
    assert!(result1.is_ok());
    
    // Second call - hits cache (would fail if database called again)
    let result2 = resolver.resolve(TenantKey::Uuid(tenant_id)).await;
    assert!(result2.is_ok());
}
```

### Integration Tests

```rust
#[tokio::test]
async fn test_concurrent_requests_coalesce() {
    let resolver = Arc::new(TenantResolver::new(db));
    
    // Spawn 100 concurrent requests for same tenant
    let tasks: Vec<_> = (0..100)
        .map(|_| {
            let r = resolver.clone();
            let id = tenant_id;
            tokio::spawn(async move {
                r.resolve(TenantKey::Uuid(id)).await
            })
        })
        .collect();
    
    // All should succeed
    for task in tasks {
        assert!(task.await.unwrap().is_ok());
    }
    
    // Database should only be hit once (check query count)
    assert_eq!(db.query_count(), 1);
}
```

### Load Tests

```bash
# Using k6 or similar
http.get('http://localhost:3000/api/tenants/me', {
    headers: { 'X-Tenant-Id': 'test-tenant' }
});
```

**Expected results:**
- Cache hit rate > 95%
- P95 latency < 10ms
- No increase in database connections
- Memory usage stable

---

## Rollback Plan

If V2 has issues:

1. **Immediate:** Set `USE_TENANT_V2=false` environment variable
2. **V1 still present** in codebase during migration period
3. **No data loss:** cache is ephemeral, will rebuild automatically
4. **Monitor:** Check error logs and metrics after rollback

---

## Configuration

### Environment Variables

```bash
# Enable V2 resolver (default: false during migration)
RUSTOK_TENANT_V2=true

# Cache configuration (optional, has defaults)
RUSTOK_TENANT_CACHE_MAX_CAPACITY=1000
RUSTOK_TENANT_CACHE_TTL_SECS=300
RUSTOK_TENANT_CACHE_IDLE_SECS=60
```

### Code Configuration

```rust
let config = TenantResolverConfig {
    max_capacity: env_or("RUSTOK_TENANT_CACHE_MAX_CAPACITY", 1_000),
    time_to_live: Duration::from_secs(
        env_or("RUSTOK_TENANT_CACHE_TTL_SECS", 300)
    ),
    time_to_idle: Duration::from_secs(
        env_or("RUSTOK_TENANT_CACHE_IDLE_SECS", 60)
    ),
};
```

---

## FAQ

### Q: What about Redis caching for multi-instance deployments?

**A:** V2 uses local in-memory cache (moka). For multi-instance deployments, consider:

1. **Option 1 (Simple):** Accept cache inconsistency window (5 min TTL)
   - Each instance has its own cache
   - Eventual consistency via TTL

2. **Option 2 (Advanced):** Add Redis layer
   - Use moka as L1 cache
   - Add Redis as L2 cache
   - Or use Redis pub/sub for invalidation (if needed)

For most use cases, **Option 1 is sufficient** because:
- Tenant data rarely changes
- 5-minute TTL is acceptable
- Database load is low for tenant lookups

### Q: What about negative caching?

**A:** V2 doesn't implement negative caching. This is intentional because:

1. **Not found** errors are less common
2. **Adds complexity** for minimal benefit
3. **TTL handles it:** Failed lookups naturally expire

If needed later, can add as a separate cache:
```rust
let negative_cache: Cache<TenantKey, ()> = Cache::builder()
    .time_to_live(Duration::from_secs(60))
    .build();
```

### Q: Performance impact?

**A:** V2 should be **faster or equal** to V1:

| Metric | V1 | V2 | Change |
|--------|----|----|--------|
| Cache hit latency | ~1-2ms | ~0.5-1ms | ðŸŸ¢ Faster |
| Cache miss latency | ~10-20ms | ~10-15ms | ðŸŸ¢ Slightly faster |
| Memory per entry | ~500B | ~300B | ðŸŸ¢ Less |
| Code complexity | High | Low | ðŸŸ¢ Simpler |

### Q: What about metrics?

**A:** V2 has **simpler metrics:**

V1 provided 10 fields:
- hits, misses, evictions
- negative_hits, negative_misses, negative_evictions
- entries, negative_entries, negative_inserts
- coalesced_requests

V2 provides 2 fields:
- entries
- weighted_size

**Rationale:** Moka handles internals well, we don't need to expose everything.

If detailed metrics are needed, can add Prometheus integration:
```rust
lazy_static! {
    static ref TENANT_CACHE_HITS: Counter = register_counter!(...).unwrap();
    static ref TENANT_CACHE_MISSES: Counter = register_counter!(...).unwrap();
}
```

---

## Checklist

- [x] Create `tenant_v2.rs` with simplified resolver
- [x] Add comprehensive unit tests
- [ ] Add integration tests
- [ ] Add load tests
- [ ] Deploy in shadow mode
- [ ] Monitor for 3 days
- [ ] Enable by default
- [ ] Remove V1 after 1 week
- [ ] Update documentation

---

## References

- [moka crate documentation](https://docs.rs/moka/)
- [Cache stampede problem](https://en.wikipedia.org/wiki/Cache_stampede)
- [REFACTORING_ROADMAP.md](./REFACTORING_ROADMAP.md) - Sprint 2, Task 2.1

---

**Last Updated:** 2026-02-12  
**Next Review:** After Phase 1 deployment
